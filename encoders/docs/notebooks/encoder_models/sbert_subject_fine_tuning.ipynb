{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence-BERT Subject  based finetuning\n",
    "\n",
    "**Model: `sentence-transformers/all-MiniLM-L6-v2`**\n",
    "\n",
    "**Purpose: Text (cosine) similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Many of the styles here are inspired by: \n",
       "    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n",
       "       \n",
       "    \n",
       "    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n",
       "    and at the request of participants, I have added it to this common import-file here.\n",
       "\n",
       "    -->\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\">\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&family=Literata&display=swap\" rel=\"stylesheet\">\n",
       "<style>\n",
       "\n",
       "\n",
       "#ipython_notebook::before{\n",
       " content:\"Neural Architectures\";\n",
       "        color: white;\n",
       "        font-weight: bold;\n",
       "        text-transform: uppercase;\n",
       "        font-family: 'Lora',serif;\n",
       "        font-size:16pt;\n",
       "        margin-bottom:15px;\n",
       "        margin-top:15px;\n",
       "           \n",
       "}\n",
       "body > #header {\n",
       "    #background: #D15555;\n",
       "    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n",
       "    opacity: 0.8;\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       ".navbar-default .navbar-nav > li > a, #kernel_indicator {\n",
       "    color: white;\n",
       "    transition: all 0.25s;\n",
       "    font-size:10pt;\n",
       "    font-family: sans-serif;\n",
       "    font-weight:normal;\n",
       "}\n",
       ".navbar-default {\n",
       "    padding-left:100px;\n",
       "    background: none;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "\n",
       "body > menubar-container {\n",
       "    background-color: wheat;\n",
       "}\n",
       "#ipython_notebook img{                                                                                        \n",
       "    display:block; \n",
       "    \n",
       "    background: url(\"https://www.supportvectors.com/wp-content/uploads/2016/03/logo-poster-smaller.png\") no-repeat;\n",
       "    background-size: contain;\n",
       "   \n",
       "    padding-left: 600px;\n",
       "    padding-right: 100px;\n",
       "    \n",
       "    -moz-box-sizing: border-box;\n",
       "    box-sizing: border-box;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "body {\n",
       " #font-family:  'Literata', serif;\n",
       "    font-family:'Lora', san-serif;\n",
       "    text-align: justify;\n",
       "    font-weight: 400;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "\n",
       "iframe{\n",
       "    width:100%;\n",
       "    min-height:600px;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "# font-family: 'Montserrat', sans-serif;\n",
       " font-family:'Lora', serif;\n",
       " font-weight: 200;\n",
       " text-transform: uppercase;\n",
       " color: #EC7063 ;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: #000080;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       "#notebook_name {\n",
       "    font-weight: 600;\n",
       "    font-size:20pt;\n",
       "    text-variant:uppercase;\n",
       "    color: wheat; \n",
       "    margin-right:20px;\n",
       "    margin-left:-500px;\n",
       "}\n",
       "#notebook_name:hover {\n",
       "background-color: salmon;\n",
       "}\n",
       "\n",
       "\n",
       ".dataframe { /* dataframe atau table */\n",
       "    background: white;\n",
       "    box-shadow: 0px 1px 2px #bbb;\n",
       "}\n",
       ".dataframe thead th, .dataframe tbody td {\n",
       "    text-align: center;\n",
       "    padding: 1em;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    transition: all 0.25s;\n",
       "    border: none;\n",
       "    position: relative;\n",
       "    top: 0;\n",
       "}\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border: none;\n",
       "    background: transparent;\n",
       "    box-shadow: 0 6px 18px #aaa;\n",
       "    z-index: 10;\n",
       "    top: -10px;\n",
       "}\n",
       ".CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n",
       "    font-family: 'Hack' , serif; \n",
       "    font-weight: 500;\n",
       "    font-size: 14pt;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "<div style=\"color:#aaa;font-size:8pt\">\n",
       "<hr/>\n",
       "&copy; SupportVectors. All rights reserved. <blockquote>This notebook is the intellectual property of SupportVectors, and part of its training material. \n",
       "Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.\n",
       "\n",
       "<b> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</b>\n",
       " </blockquote>\n",
       " <hr/>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 09:24:24.353762: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-03 09:24:24.374644: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-03 09:24:24.381062: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-03 09:24:24.398915: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-03 09:24:25.369116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from svlearn.config.configuration import ConfigurationMixin\n",
    "from svlearn.encoder_models.sbert_subjects_full_ft import convert_to_pair_dataset, sampled_dataset, get_evaluator\n",
    "from svlearn.util.hf_text_util import get_train_test_lists, tuples_list_to_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No configuration file specified. Trying the default location\n",
      "WARNING:root:Loading configuration from /home/chandar/fine-tuning/fine-tuning-config.yaml if it exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chandar/fine-tuning/docs/notebooks/encoder_models\n"
     ]
    }
   ],
   "source": [
    "# Get the CommentedMap of config (contains paths for data and results directories)\n",
    "config = ConfigurationMixin().load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model and Dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Get the base sentence transformer model\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentence1 = \"The rate of change of displacement is velocity\"\n",
    "sentence2 = \"Kidney plays an important role in purifying blood\"\n",
    "sentence3 = \"Many countries obtained their freedom by 1950\"\n",
    "sentence4 = \"Force is proportional to mass\"\n",
    "sentence5 = \"Vaccines train our immune system to create antibodies\"\n",
    "sentence6 = \"World war 2 was a global conflict between two coalitions - the allies and the axis powers\"\n",
    "\n",
    "sentences = [sentence1, sentence4, sentence2, sentence5, sentence3, sentence6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000,  0.3542, -0.0164,  0.0284,  0.0843, -0.0478],\n",
      "        [ 0.3542,  1.0000, -0.0098,  0.1015,  0.0422,  0.1267],\n",
      "        [-0.0164, -0.0098,  1.0000,  0.1488, -0.0401, -0.0213],\n",
      "        [ 0.0284,  0.1015,  0.1488,  1.0000,  0.0531,  0.0239],\n",
      "        [ 0.0843,  0.0422, -0.0401,  0.0531,  1.0000,  0.1837],\n",
      "        [-0.0478,  0.1267, -0.0213,  0.0239,  0.1837,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(sentences)\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the evaluator to evaluate the model before and after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4094089adb6f4149aee7442f238f456c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9333 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2f38893a9c4529a26b57d4a5d5590c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9333 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbff0ae6c9349bf97eb46ffc69ac160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9333 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pick chunks labeled with subjects (biology, physics, history assigned to labels 0, 1, 2 respectively)\n",
    "_, test = get_train_test_lists(cfg=config)\n",
    "\n",
    "# Convert to Dataset format\n",
    "test_dataset = tuples_list_to_dataset(test)\n",
    "\n",
    "# Sample to max of 500 per label so that the paired dataset is having max of 1500*1499/2\n",
    "test_dataset = sampled_dataset(test_dataset)\n",
    "\n",
    "# Create the paired dataset consisting of (sentence1, sentence2, score) from the text/label dataset\n",
    "test_dataset = convert_to_pair_dataset(test_dataset)\n",
    "\n",
    "binary_acc_evaluator = get_evaluator(test_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cosine_accuracy': 0.8064,\n",
       " 'cosine_accuracy_threshold': 0.12211808562278748,\n",
       " 'cosine_f1': 0.6848559166155733,\n",
       " 'cosine_f1_threshold': 0.09713000059127808,\n",
       " 'cosine_precision': 0.6907854050711194,\n",
       " 'cosine_recall': 0.6790273556231003,\n",
       " 'cosine_ap': 0.768099852927515,\n",
       " 'dot_accuracy': 0.8064,\n",
       " 'dot_accuracy_threshold': 0.12211807072162628,\n",
       " 'dot_f1': 0.6848559166155733,\n",
       " 'dot_f1_threshold': 0.09712999314069748,\n",
       " 'dot_precision': 0.6907854050711194,\n",
       " 'dot_recall': 0.6790273556231003,\n",
       " 'dot_ap': 0.7680998529275151,\n",
       " 'manhattan_accuracy': 0.8002,\n",
       " 'manhattan_accuracy_threshold': 20.343429565429688,\n",
       " 'manhattan_f1': 0.6668771708241238,\n",
       " 'manhattan_f1_threshold': 20.812236785888672,\n",
       " 'manhattan_precision': 0.6938239159001314,\n",
       " 'manhattan_recall': 0.6419452887537994,\n",
       " 'manhattan_ap': 0.7550996576920808,\n",
       " 'euclidean_accuracy': 0.8064,\n",
       " 'euclidean_accuracy_threshold': 1.3250523805618286,\n",
       " 'euclidean_f1': 0.6848559166155733,\n",
       " 'euclidean_f1_threshold': 1.343778133392334,\n",
       " 'euclidean_precision': 0.6907854050711194,\n",
       " 'euclidean_recall': 0.6790273556231003,\n",
       " 'euclidean_ap': 0.7680996171965008,\n",
       " 'max_accuracy': 0.8064,\n",
       " 'max_accuracy_threshold': 20.343429565429688,\n",
       " 'max_f1': 0.6848559166155733,\n",
       " 'max_f1_threshold': 20.812236785888672,\n",
       " 'max_precision': 0.6938239159001314,\n",
       " 'max_recall': 0.6790273556231003,\n",
       " 'max_ap': 0.7680998529275151}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = binary_acc_evaluator(model)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the fine-tuned model and repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No configuration file specified. Trying the default location\n",
      "WARNING:root:Loading configuration from /home/chandar/fine-tuning/fine-tuning-config.yaml if it exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chandar/fine-tuning/docs/notebooks/encoder_models\n",
      "tensor([[ 1.0000,  0.4692, -0.2819, -0.2451, -0.0771, -0.1496],\n",
      "        [ 0.4692,  1.0000, -0.1757, -0.1116, -0.0724, -0.0366],\n",
      "        [-0.2819, -0.1757,  1.0000,  0.4889, -0.1105, -0.1134],\n",
      "        [-0.2451, -0.1116,  0.4889,  1.0000, -0.1291, -0.1757],\n",
      "        [-0.0771, -0.0724, -0.1105, -0.1291,  1.0000,  0.5889],\n",
      "        [-0.1496, -0.0366, -0.1134, -0.1757,  0.5889,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationMixin().load_config()\n",
    "results_dir = config[\"paths\"][\"results\"]\n",
    "# Update Checkpoint Folder\n",
    "finetuned_model_dir = f'{results_dir}/subject-based-encoder/checkpoint-2000'   \n",
    "# Load the model\n",
    "model = SentenceTransformer(finetuned_model_dir)\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cosine_accuracy': 0.9818,\n",
       " 'cosine_accuracy_threshold': 0.24900028109550476,\n",
       " 'cosine_f1': 0.972549019607843,\n",
       " 'cosine_f1_threshold': 0.15513762831687927,\n",
       " 'cosine_precision': 0.9652694610778443,\n",
       " 'cosine_recall': 0.9799392097264438,\n",
       " 'cosine_ap': 0.9960457719069957,\n",
       " 'dot_accuracy': 0.9818,\n",
       " 'dot_accuracy_threshold': 0.24900034070014954,\n",
       " 'dot_f1': 0.972549019607843,\n",
       " 'dot_f1_threshold': 0.15513765811920166,\n",
       " 'dot_precision': 0.9652694610778443,\n",
       " 'dot_recall': 0.9799392097264438,\n",
       " 'dot_ap': 0.9960457719069957,\n",
       " 'manhattan_accuracy': 0.9822,\n",
       " 'manhattan_accuracy_threshold': 19.82466697692871,\n",
       " 'manhattan_f1': 0.9731523378582202,\n",
       " 'manhattan_f1_threshold': 20.397037506103516,\n",
       " 'manhattan_precision': 0.9658682634730539,\n",
       " 'manhattan_recall': 0.9805471124620061,\n",
       " 'manhattan_ap': 0.9959320334580082,\n",
       " 'euclidean_accuracy': 0.9818,\n",
       " 'euclidean_accuracy_threshold': 1.2255607843399048,\n",
       " 'euclidean_f1': 0.972549019607843,\n",
       " 'euclidean_f1_threshold': 1.2998931407928467,\n",
       " 'euclidean_precision': 0.9652694610778443,\n",
       " 'euclidean_recall': 0.9799392097264438,\n",
       " 'euclidean_ap': 0.9960457719069957,\n",
       " 'max_accuracy': 0.9822,\n",
       " 'max_accuracy_threshold': 19.82466697692871,\n",
       " 'max_f1': 0.9731523378582202,\n",
       " 'max_f1_threshold': 20.397037506103516,\n",
       " 'max_precision': 0.9658682634730539,\n",
       " 'max_recall': 0.9805471124620061,\n",
       " 'max_ap': 0.9960457719069957}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = binary_acc_evaluator(model)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fine_tuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
